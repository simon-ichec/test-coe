[{"@context": "https://schema.org", "@graph": [{"@type": "Event", "name": "Advanced HPC Workshop for MPG and NOMAD", "url": "https://www.mpcdf.mpg.de/events/31623/14192", "description": "This workshop helps HPC developers to better manage, debug and profile their code. One day is dedicated to GPU programming.\n\nMPCDF organizes an advanced HPC workshop for users of the MPG and of the EU Center of Excellence NOMAD from Tuesday, November 22nd until Thursday, November 24th, 2022. We plan to give the lectures in a hybrid fashion, onsite and streamed online. The hands-on part will be onsite at the MPCDF in Garching if the pandemic situation permits. The main topics of the lectures are\n\n  * Debugging and profiling of CPU and GPU codes\n  * Porting codes to GPU-accelerated systems\n\n\n\nAs a prerequisite, we require participants to have an account for the HPC machines of MPCDF and are already familiar with accessing, building and running their codes. The workshop is open to code developers of the NOMAD CoE, who will specifically learn about GPUs as the main building blocks for (pre-)exascale systems and how to develop and optimize codes on such platforms.\n\nIf you are interested in bringing in your own code to work with the experts and to apply the techniques and tools taught in the lectures, please apply by adding a short description of your code and specific goals in the registration form. The entire Thursday, November 24th is dedicated to working on the selected code projects.\n\nThe workshop will be given by members of the application group of the MPCDF together with experts from Intel and Nvidia. The registration is open and can be accessed via the link on the left. The deadline for registration for the lectures is November 12th, for pure online participation, you can register until November 18th.\n\nThe applicants for the hands-on day are asked to test the building of the code on Raven and to prepare a representative test case for the problem that they want to inspect (ideally the test can be run on a single Raven node, either GPU or CPU) in advance of the workshop. Assistance by MPCDF is provided on request.", "eventAttendanceMode": "https://schema.org/MixedEventAttendanceMode", "eventStatus": "https://schema.org/EventScheduled", "image": {"@type": "ImageObject", "representativeOfPage": "True", "url": "images/FocusCoE_placeholder.webp", "width": 720, "height": 231}, "doorTime": "2022-11-22T09:00:00+0100", "startDate": "2022-11-22T09:00:00+0100", "endDate": "2022-11-24T17:00:00+0100", "@id": "https://hpc-portal.eu/node/1445", "isAccessibleForFree": "True", "location": {"@type": "VirtualLocation", "url": "https://www.mpcdf.mpg.de/events/31623/14192", "geo": {"@type": "GeoCoordinates", "latitude": "48.2612889", "longitude": "11.671093"}}, "language": ["English"], "sector": ["Research and Academia", "Industry"], "country": ["Germany"], "projects": ["NOMAD"], "level": ["Intermediate", "Advanced"], "online": ["Live (synchronous)"], "html_description": "<p>This workshop helps HPC developers to better manage, debug and profile their code. One day is dedicated to GPU programming.</p> <p>MPCDF organizes an advanced HPC workshop for users of the MPG and of the <a href=\"https://www.nomad-coe.eu/\">EU Center of Excellence NOMAD</a> from Tuesday, November 22nd until Thursday, November 24th, 2022. We plan to give the lectures in a hybrid fashion, onsite and streamed online. The hands-on part will be onsite at the MPCDF in Garching if the pandemic situation permits. The main topics of the lectures are</p> <ul> <li>Debugging and profiling of CPU and GPU codes</li> <li>Porting codes to GPU-accelerated systems</li> </ul> <p>As a prerequisite, we require participants to have an account for the HPC machines of MPCDF and are already familiar with accessing, building and running their codes. The workshop is open to code developers of the NOMAD CoE, who will specifically learn about GPUs as the main building blocks for (pre-)exascale systems and how to develop and optimize codes on such platforms.</p> <p>If you are interested in bringing in your own code to work with the experts and to apply the techniques and tools taught in the lectures, please apply by adding a short description of your code and specific goals in the registration form. The entire Thursday, November 24th is dedicated to working on the selected code projects.</p> <p>The workshop will be given by members of the application group of the MPCDF together with experts from Intel and Nvidia. The registration is open and can be accessed via the link on the left. The deadline for registration for the lectures is November 12th, for pure online participation, you can register until November 18th.</p> <p>The applicants for the hands-on day are asked to test the building of the code on Raven and to prepare a representative test case for the problem that they want to inspect (ideally the test can be run on a single Raven node, either GPU or CPU) in advance of the workshop. Assistance by MPCDF is provided on request.</p>", "markdown_description": "This workshop helps HPC developers to better manage, debug and profile their code. One day is dedicated to GPU programming.\n\nMPCDF organizes an advanced HPC workshop for users of the MPG and of the [EU Center of Excellence NOMAD](https://www.nomad-coe.eu/) from Tuesday, November 22nd until Thursday, November 24th, 2022. We plan to give the lectures in a hybrid fashion, onsite and streamed online. The hands-on part will be onsite at the MPCDF in Garching if the pandemic situation permits. The main topics of the lectures are\n\n  * Debugging and profiling of CPU and GPU codes\n  * Porting codes to GPU-accelerated systems\n\n\n\nAs a prerequisite, we require participants to have an account for the HPC machines of MPCDF and are already familiar with accessing, building and running their codes. The workshop is open to code developers of the NOMAD CoE, who will specifically learn about GPUs as the main building blocks for (pre-)exascale systems and how to develop and optimize codes on such platforms.\n\nIf you are interested in bringing in your own code to work with the experts and to apply the techniques and tools taught in the lectures, please apply by adding a short description of your code and specific goals in the registration form. The entire Thursday, November 24th is dedicated to working on the selected code projects.\n\nThe workshop will be given by members of the application group of the MPCDF together with experts from Intel and Nvidia. The registration is open and can be accessed via the link on the left. The deadline for registration for the lectures is November 12th, for pure online participation, you can register until November 18th.\n\nThe applicants for the hands-on day are asked to test the building of the code on Raven and to prepare a representative test case for the problem that they want to inspect (ideally the test can be run on a single Raven node, either GPU or CPU) in advance of the workshop. Assistance by MPCDF is provided on request.", "summary": "This workshop helps HPC developers to better manage, debug and profile their code. One day is dedicated to GPU programming.\n\nMPCDF..."}]}, {"@context": "https://schema.org", "@graph": [{"@type": "Event", "name": "Charting large materials dataspaces: AI methods and scalability", "url": "https://www.cecam.org/workshop-details/1167", "description": "Organisers \n\n  * Luca Ghiringhelli (NOMAD Laboratory at the Fritz Haber Institute of the Max Planck Society and Humboldt University, Berlin)\n  * James Kermode (University of Warwick)\n  * Markus Rampp (Max Planck Computing and Data Facility (MPCDF))\n\n\n\nAcross a wide range of fields and in particular in materials science, there is increasing awareness that big data is a fundamental resource for fostering deeper understanding of physical systems and ensuring reproducibility of calculations.\n\nIt is crucial to realize that \u201cbig\u201d does not refer only to the sheer amount of data, but also to their complexity. For example, in materials science, a material is typically characterized by an intricate hierarchy of observables including ensemble averages at various thermodynamic conditions. Another crucial aspect is the need to validate and quantify uncertainty, i.e., being able to assign to any single entry in the database a level of accuracy so that data points from disparate sources can be used concurrently in an analysis.\n\nSuch awareness has motivated the creation of large computational materials-science databases. Some are \u201cproject-based\u201d, i.e., collections of high-throughput scans of given materials classes (e.g., AFLOW [1], Materials Project [2], OQMD [3]), others collect data from heterogeneous sources (e.g., NOMAD [4], Materials Cloud [5]).\n\nIn order for the data to be (re-)usable for new analyses and possibly discoveries, they have to comply with the so-called FAIR (findable - accessible - interoperable - reusable/repurposable/recyclable) principles [6]. \n\nThis requires complex, hierarchical metadata structures that annotate the data, so that the users know the provenance (settings, purpose) of a calculation in order to judge whether an entry can be part of a dataset to be analysed [7].\n\nThe complexity and extent of the existing databases, which can only grow in both respects, reveals a rarely addressed challenge: the possibility to efficiently _explore_ the databases themselves in order to reveal patterns and trends.\n\nHere, exploration refers specifically to the possibility of producing dynamic, visual maps of the databases\u2019 content. For instance, a user may be looking for ternary materials, not containing radioactive species, and would like to understand how diverse are the entries, i.e., whether they are somewhat uniformly spanning the materials space or are clustered into classes, where understanding what is common among class\u2019 members is a challenge in itself.\n\nThis and similar kinds of questions call for interactive, dynamic, and intelligent (i.e., artificial-intelligent-driven) tools, which are also efficient, i.e., they are able to propose a meaningful solution within seconds. \n\nIn summary, in order to harvest the yet unhearted richness contained in presently known and future materials-science data, four pillars need to be concurrently developed:\n\n  * FAIR-compliant materials databases\n  * Identification of proper descriptors and metrics for capturing the similarity amongst materials, including the complex restructuring occurring at varying environmental conditions [8]\n  * Artificial-intelligence (AI) approaches for exploratory analysis: clustering, dimension reduction and corresponding visualization that can reveal hidden patterns [9]\n  * Scalable implementations, combining clever choice of the hardware as well as algorithmic speed-up (e.g., landmarking) [10]\n\n\n\nIn this workshop, experts in all these aspects, not necessarily limited to materials-science applications, will interact to confront ideas and solutions for performing flexible, interactive, efficient, and insightful analyses of materials databases.\n\n## References\n\n[1] S. Curtarolo, W. Setyawan, G. Hart, M. Jahnatek, R. Chepulskii, R. Taylor, S. Wang, J. Xue, K. Yang, O. Levy, M. Mehl, H. Stokes, D. Demchenko, D. Morgan, Computational Materials Science, **58** , 218-226 (2012)  \n[2] A. Jain, S. Ong, G. Hautier, W. Chen, W. Richards, S. Dacek, S. Cholia, D. Gunter, D. Skinner, G. Ceder, K. Persson, APL Materials, **1** , 011002 (2013)  \n[3] J. Saal, S. Kirklin, M. Aykol, B. Meredig, C. Wolverton, JOM, **65** , 1501-1509 (2013)  \n[4] C. Draxl, M. Scheffler, MRS Bull., **43** , 676-682 (2018)  \n[5] L. Talirz, S. Kumbhar, E. Passaro, A. Yakutovich, V. Granata, F. Gargiulo, M. Borelli, M. Uhrin, S. Huber, S. Zoupanos, C. Adorf, C. Andersen, O. Sch\u00fctt, C. Pignedoli, D. Passerone, J. VandeVondele, T. Schulthess, B. Smit, G. Pizzi, N. Marzari, Sci. Data., **7** , 299 (2020)  \n[6] M. Wilkinson, M. Dumontier, I. Aalbersberg, G. Appleton, M. Axton, A. Baak, N. Blomberg, J. Boiten, L. da Silva Santos, P. Bourne, J. Bouwman, A. Brookes, T. Clark, M. Crosas, I. Dillo, O. Dumon, S. Edmunds, C. Evelo, R. Finkers, A. Gonzalez-Beltran, A. Gray, P. Groth, C. Goble, J. Grethe, J. Heringa, P. \u2019t Hoen, R. Hooft, T. Kuhn, R. Kok, J. Kok, S. Lusher, M. Martone, A. Mons, A. Packer, B. Persson, P. Rocca-Serra, M. Roos, R. van Schaik, S. Sansone, E. Schultes, T. Sengstag, T. Slater, G. Strawn, M. Swertz, M. Thompson, J. van der Lei, E. van Mulligen, J. Velterop, A. Waagmeester, P. Wittenburg, K. Wolstencroft, J. Zhao, B. Mons, Sci. Data., **3** , 160018 (2016)  \n[7] L. Ghiringhelli, C. Carbogno, S. Levchenko, F. Mohamed, G. Huhs, M. L\u00fcders, M. Oliveira, M. Scheffler, npj. Comput. Mater., **3** , 46 (2017)  \n[8] A. Bart\u00f3k, S. De, C. Poelking, N. Bernstein, J. Kermode, G. Cs\u00e1nyi, M. Ceriotti, Sci. Adv., **3** , e1701816 (2017)  \n[9] M. Ceriotti, J. Chem. Phys., **150** , 150901 (2019)  \n[10] S. Idreos, O. Papaemmanouil, S. Chaudhuri, Overview of Data Exploration Techniques, 2015", "eventAttendanceMode": "https://schema.org/OfflineEventAttendanceMode", "eventStatus": "https://schema.org/EventScheduled", "image": {"@type": "ImageObject", "representativeOfPage": "True", "url": "images/FocusCoE_placeholder.webp", "width": 720, "height": 231}, "doorTime": "2022-10-10T09:00:00+0200", "startDate": "2022-10-10T09:00:00+0200", "endDate": "2022-10-12T17:00:00+0200", "@id": "https://hpc-portal.eu/node/1444", "isAccessibleForFree": "True", "location": {"@type": "VirtualLocation", "url": "https://www.cecam.org/workshop-details/1167", "geo": {"@type": "GeoCoordinates", "latitude": "45.1901956", "longitude": "5.767295"}}, "language": ["English"], "sector": ["Research and Academia", "Industry"], "country": ["France"], "projects": ["NOMAD"], "level": ["Beginner", "Intermediate", "Advanced"], "html_description": "Organisers <ul> <li>Luca Ghiringhelli (NOMAD Laboratory at the Fritz Haber Institute of the Max Planck Society and Humboldt University, Berlin)</li> <li>James Kermode (University of Warwick)</li> <li>Markus Rampp (Max Planck Computing and Data Facility (MPCDF))</li> </ul> <p>Across a wide range of fields and in particular in materials science, there is increasing awareness that big data is a fundamental resource for fostering deeper understanding of physical systems and ensuring reproducibility of calculations.</p> <p>It is crucial to realize that \u201cbig\u201d does not refer only to the sheer amount of data, but also to their complexity. For example, in materials science, a material is typically characterized by an intricate hierarchy of observables including ensemble averages at various thermodynamic conditions. Another crucial aspect is the need to validate and quantify uncertainty, i.e., being able to assign to any single entry in the database a level of accuracy so that data points from disparate sources can be used concurrently in an analysis.</p> <p>Such awareness has motivated the creation of large computational materials-science databases. Some are \u201cproject-based\u201d, i.e., collections of high-throughput scans of given materials classes (e.g., AFLOW [1], Materials Project [2], OQMD [3]), others collect data from heterogeneous sources (e.g., NOMAD [4], Materials Cloud [5]).</p> <p>In order for the data to be (re-)usable for new analyses and possibly discoveries, they have to comply with the so-called FAIR (findable - accessible - interoperable - reusable/repurposable/recyclable) principles [6]. </p> <p>This requires complex, hierarchical metadata structures that annotate the data, so that the users know the provenance (settings, purpose) of a calculation in order to judge whether an entry can be part of a dataset to be analysed [7].</p> <p>The complexity and extent of the existing databases, which can only grow in both respects, reveals a rarely addressed challenge: the possibility to efficiently <em>explore</em> the databases themselves in order to reveal patterns and trends.</p> <p>Here, exploration refers specifically to the possibility of producing dynamic, visual maps of the databases\u2019 content. For instance, a user may be looking for ternary materials, not containing radioactive species, and would like to understand how diverse are the entries, i.e., whether they are somewhat uniformly spanning the materials space or are clustered into classes, where understanding what is common among class\u2019 members is a challenge in itself.</p> <p>This and similar kinds of questions call for interactive, dynamic, and intelligent (i.e., artificial-intelligent-driven) tools, which are also efficient, i.e., they are able to propose a meaningful solution within seconds. </p> <p>In summary, in order to harvest the yet unhearted richness contained in presently known and future materials-science data, four pillars need to be concurrently developed:</p> <ul> <li>FAIR-compliant materials databases</li> <li>Identification of proper descriptors and metrics for capturing the similarity amongst materials, including the complex restructuring occurring at varying environmental conditions [8]</li> <li>Artificial-intelligence (AI) approaches for exploratory analysis: clustering, dimension reduction and corresponding visualization that can reveal hidden patterns [9]</li> <li>Scalable implementations, combining clever choice of the hardware as well as algorithmic speed-up (e.g., landmarking) [10]</li> </ul> <p>In this workshop, experts in all these aspects, not necessarily limited to materials-science applications, will interact to confront ideas and solutions for performing flexible, interactive, efficient, and insightful analyses of materials databases.</p> <h2>References</h2> <p><a href=\"http://dx.doi.org/10.1016/j.commatsci.2012.02.005\">[1] S. Curtarolo, W. Setyawan, G. Hart, M. Jahnatek, R. Chepulskii, R. Taylor, S. Wang, J. Xue, K. Yang, O. Levy, M. Mehl, H. Stokes, D. Demchenko, D. Morgan, Computational Materials Science, <strong>58</strong>, 218-226 (2012)</a><br> <a href=\"http://dx.doi.org/10.1063/1.4812323\">[2] A. Jain, S. Ong, G. Hautier, W. Chen, W. Richards, S. Dacek, S. Cholia, D. Gunter, D. Skinner, G. Ceder, K. Persson, APL Materials, <strong>1</strong>, 011002 (2013)</a><br> <a href=\"http://dx.doi.org/10.1007/s11837-013-0755-4\">[3] J. Saal, S. Kirklin, M. Aykol, B. Meredig, C. Wolverton, JOM, <strong>65</strong>, 1501-1509 (2013)</a><br> <a href=\"http://dx.doi.org/10.1557/mrs.2018.208\">[4] C. Draxl, M. Scheffler, MRS Bull., <strong>43</strong>, 676-682 (2018)</a><br> <a href=\"http://dx.doi.org/10.1038/s41597-020-00637-5\">[5] L. Talirz, S. Kumbhar, E. Passaro, A. Yakutovich, V. Granata, F. Gargiulo, M. Borelli, M. Uhrin, S. Huber, S. Zoupanos, C. Adorf, C. Andersen, O. Sch\u00fctt, C. Pignedoli, D. Passerone, J. VandeVondele, T. Schulthess, B. Smit, G. Pizzi, N. Marzari, Sci. Data., <strong>7</strong>, 299 (2020)</a><br> <a href=\"http://dx.doi.org/10.1038/sdata.2016.18\">[6] M. Wilkinson, M. Dumontier, I. Aalbersberg, G. Appleton, M. Axton, A. Baak, N. Blomberg, J. Boiten, L. da Silva Santos, P. Bourne, J. Bouwman, A. Brookes, T. Clark, M. Crosas, I. Dillo, O. Dumon, S. Edmunds, C. Evelo, R. Finkers, A. Gonzalez-Beltran, A. Gray, P. Groth, C. Goble, J. Grethe, J. Heringa, P. \u2019t Hoen, R. Hooft, T. Kuhn, R. Kok, J. Kok, S. Lusher, M. Martone, A. Mons, A. Packer, B. Persson, P. Rocca-Serra, M. Roos, R. van Schaik, S. Sansone, E. Schultes, T. Sengstag, T. Slater, G. Strawn, M. Swertz, M. Thompson, J. van der Lei, E. van Mulligen, J. Velterop, A. Waagmeester, P. Wittenburg, K. Wolstencroft, J. Zhao, B. Mons, Sci. Data., <strong>3</strong>, 160018 (2016)</a><br> <a href=\"http://dx.doi.org/10.1038/s41524-017-0048-5\">[7] L. Ghiringhelli, C. Carbogno, S. Levchenko, F. Mohamed, G. Huhs, M. L\u00fcders, M. Oliveira, M. Scheffler, npj. Comput. Mater., <strong>3</strong>, 46 (2017)</a><br> <a href=\"http://dx.doi.org/10.1126/sciadv.1701816\">[8] A. Bart\u00f3k, S. De, C. Poelking, N. Bernstein, J. Kermode, G. Cs\u00e1nyi, M. Ceriotti, Sci. Adv., <strong>3</strong>, e1701816 (2017)</a><br> <a href=\"http://dx.doi.org/10.1063/1.5091842\">[9] M. Ceriotti, J. Chem. Phys., <strong>150</strong>, 150901 (2019)</a><br> <a href=\"http://dx.doi.org/10.1145/2723372.2731084\">[10] S. Idreos, O. Papaemmanouil, S. Chaudhuri, Overview of Data Exploration Techniques, 2015</a></p>", "markdown_description": "Organisers \n\n  * Luca Ghiringhelli (NOMAD Laboratory at the Fritz Haber Institute of the Max Planck Society and Humboldt University, Berlin)\n  * James Kermode (University of Warwick)\n  * Markus Rampp (Max Planck Computing and Data Facility (MPCDF))\n\n\n\nAcross a wide range of fields and in particular in materials science, there is increasing awareness that big data is a fundamental resource for fostering deeper understanding of physical systems and ensuring reproducibility of calculations.\n\nIt is crucial to realize that \u201cbig\u201d does not refer only to the sheer amount of data, but also to their complexity. For example, in materials science, a material is typically characterized by an intricate hierarchy of observables including ensemble averages at various thermodynamic conditions. Another crucial aspect is the need to validate and quantify uncertainty, i.e., being able to assign to any single entry in the database a level of accuracy so that data points from disparate sources can be used concurrently in an analysis.\n\nSuch awareness has motivated the creation of large computational materials-science databases. Some are \u201cproject-based\u201d, i.e., collections of high-throughput scans of given materials classes (e.g., AFLOW [1], Materials Project [2], OQMD [3]), others collect data from heterogeneous sources (e.g., NOMAD [4], Materials Cloud [5]).\n\nIn order for the data to be (re-)usable for new analyses and possibly discoveries, they have to comply with the so-called FAIR (findable - accessible - interoperable - reusable/repurposable/recyclable) principles [6]. \n\nThis requires complex, hierarchical metadata structures that annotate the data, so that the users know the provenance (settings, purpose) of a calculation in order to judge whether an entry can be part of a dataset to be analysed [7].\n\nThe complexity and extent of the existing databases, which can only grow in both respects, reveals a rarely addressed challenge: the possibility to efficiently _explore_ the databases themselves in order to reveal patterns and trends.\n\nHere, exploration refers specifically to the possibility of producing dynamic, visual maps of the databases\u2019 content. For instance, a user may be looking for ternary materials, not containing radioactive species, and would like to understand how diverse are the entries, i.e., whether they are somewhat uniformly spanning the materials space or are clustered into classes, where understanding what is common among class\u2019 members is a challenge in itself.\n\nThis and similar kinds of questions call for interactive, dynamic, and intelligent (i.e., artificial-intelligent-driven) tools, which are also efficient, i.e., they are able to propose a meaningful solution within seconds. \n\nIn summary, in order to harvest the yet unhearted richness contained in presently known and future materials-science data, four pillars need to be concurrently developed:\n\n  * FAIR-compliant materials databases\n  * Identification of proper descriptors and metrics for capturing the similarity amongst materials, including the complex restructuring occurring at varying environmental conditions [8]\n  * Artificial-intelligence (AI) approaches for exploratory analysis: clustering, dimension reduction and corresponding visualization that can reveal hidden patterns [9]\n  * Scalable implementations, combining clever choice of the hardware as well as algorithmic speed-up (e.g., landmarking) [10]\n\n\n\nIn this workshop, experts in all these aspects, not necessarily limited to materials-science applications, will interact to confront ideas and solutions for performing flexible, interactive, efficient, and insightful analyses of materials databases.\n\n## References\n\n[[1] S. Curtarolo, W. Setyawan, G. Hart, M. Jahnatek, R. Chepulskii, R. Taylor, S. Wang, J. Xue, K. Yang, O. Levy, M. Mehl, H. Stokes, D. Demchenko, D. Morgan, Computational Materials Science, **58** , 218-226 (2012)](http://dx.doi.org/10.1016/j.commatsci.2012.02.005)  \n[[2] A. Jain, S. Ong, G. Hautier, W. Chen, W. Richards, S. Dacek, S. Cholia, D. Gunter, D. Skinner, G. Ceder, K. Persson, APL Materials, **1** , 011002 (2013)](http://dx.doi.org/10.1063/1.4812323)  \n[[3] J. Saal, S. Kirklin, M. Aykol, B. Meredig, C. Wolverton, JOM, **65** , 1501-1509 (2013)](http://dx.doi.org/10.1007/s11837-013-0755-4)  \n[[4] C. Draxl, M. Scheffler, MRS Bull., **43** , 676-682 (2018)](http://dx.doi.org/10.1557/mrs.2018.208)  \n[[5] L. Talirz, S. Kumbhar, E. Passaro, A. Yakutovich, V. Granata, F. Gargiulo, M. Borelli, M. Uhrin, S. Huber, S. Zoupanos, C. Adorf, C. Andersen, O. Sch\u00fctt, C. Pignedoli, D. Passerone, J. VandeVondele, T. Schulthess, B. Smit, G. Pizzi, N. Marzari, Sci. Data., **7** , 299 (2020)](http://dx.doi.org/10.1038/s41597-020-00637-5)  \n[[6] M. Wilkinson, M. Dumontier, I. Aalbersberg, G. Appleton, M. Axton, A. Baak, N. Blomberg, J. Boiten, L. da Silva Santos, P. Bourne, J. Bouwman, A. Brookes, T. Clark, M. Crosas, I. Dillo, O. Dumon, S. Edmunds, C. Evelo, R. Finkers, A. Gonzalez-Beltran, A. Gray, P. Groth, C. Goble, J. Grethe, J. Heringa, P. \u2019t Hoen, R. Hooft, T. Kuhn, R. Kok, J. Kok, S. Lusher, M. Martone, A. Mons, A. Packer, B. Persson, P. Rocca-Serra, M. Roos, R. van Schaik, S. Sansone, E. Schultes, T. Sengstag, T. Slater, G. Strawn, M. Swertz, M. Thompson, J. van der Lei, E. van Mulligen, J. Velterop, A. Waagmeester, P. Wittenburg, K. Wolstencroft, J. Zhao, B. Mons, Sci. Data., **3** , 160018 (2016)](http://dx.doi.org/10.1038/sdata.2016.18)  \n[[7] L. Ghiringhelli, C. Carbogno, S. Levchenko, F. Mohamed, G. Huhs, M. L\u00fcders, M. Oliveira, M. Scheffler, npj. Comput. Mater., **3** , 46 (2017)](http://dx.doi.org/10.1038/s41524-017-0048-5)  \n[[8] A. Bart\u00f3k, S. De, C. Poelking, N. Bernstein, J. Kermode, G. Cs\u00e1nyi, M. Ceriotti, Sci. Adv., **3** , e1701816 (2017)](http://dx.doi.org/10.1126/sciadv.1701816)  \n[[9] M. Ceriotti, J. Chem. Phys., **150** , 150901 (2019)](http://dx.doi.org/10.1063/1.5091842)  \n[[10] S. Idreos, O. Papaemmanouil, S. Chaudhuri, Overview of Data Exploration Techniques, 2015](http://dx.doi.org/10.1145/2723372.2731084)", "summary": "Organisers \n\n  * Luca Ghiringhelli (NOMAD Laboratory at the Fritz Haber Institute of the Max Planck Society and Humboldt University,..."}]}, {"@context": "https://schema.org", "@graph": [{"@type": "Event", "name": "Co-Design for HPC in Computational Materials and Molecular Science", "url": "https://www.cecam.org/workshop-details/1113", "description": "The Workshop on HPC (High Performance Computing) Co-design in Computational Materials and Molecular Science was initiated and is led by the NOMAD Center of Excellence (www.nomad-coe.eu), and is organised by NOMAD in collaboration with the BioExcel, MAX, and TREX CoEs. \n\nThe workshop will gather contributions from leading scientists, technologies, and SW engineers from the fields of academia, HPC centres, HW-vendors, and industry. The workshop covers a broad range of current topics, taking materials and molecular science codes as reference HPC applications and possible co-design vehicles. \n\nThe topics to be covered are:\n\n(1) existing examples of HPC co-design in materials and molecular science,\n\n(2) co-design of general purpose and domain-specific libraries, kernels, and mini-apps, and\n\n(3) the perspective of hardware manufacturers, integrators, and data center owners.\n\nThe workshop will focus in particular on, and attempt to draw conclusions about:\n\n(1) the relationship between algorithms and computer architectures in materials science,\n\n(2) the connection between parallel programming technologies and runtime systems, and\n\n(3) the interplay of the above layers for a wide spectrum of computer architectures, within the selected scientific domain. \n\nWe aim to identify how scientific software developers in materials science can influence hardware manufacturers as well as middleware and system-level software developers, and vice versa. In particular, we seek to determine how co-design is employed in the development of the new HPC processors and of the related software stack, including with respect to compilers and optimized libraries, schedulers and IO, and container technologies. \n\nHardware HPC vendors and integrators will share their vision on co-design, while key people from the scientific software development community will discuss the adoption of state-of-the-art technologies when porting their codes on emerging computer architectures. Consequently, the workshop will provide a rare and valuable opportunity to foster close contacts and the exchange of ideas between the scientific and technical communities.", "eventAttendanceMode": "https://schema.org/OfflineEventAttendanceMode", "eventStatus": "https://schema.org/EventScheduled", "image": {"@type": "ImageObject", "representativeOfPage": "True", "url": "tmp_images/0d528369982d5720939d0f8b1b944839.webp", "width": 720, "height": 359}, "doorTime": "2022-10-03T09:00:00+0200", "startDate": "2022-10-03T09:00:00+0200", "endDate": "2022-10-05T17:00:00+0200", "@id": "https://hpc-portal.eu/node/1443", "isAccessibleForFree": "True", "location": {"@type": "VirtualLocation", "url": "https://www.cecam.org/workshop-details/1113", "geo": {"@type": "GeoCoordinates", "latitude": "46.520216136934", "longitude": "6.5722103374848"}}, "language": ["English"], "sector": ["Research and Academia", "Industry"], "country": ["Switzerland"], "projects": ["BioExcel-2", "MaX", "NOMAD", "TREX"], "level": ["Beginner", "Intermediate", "Advanced"], "html_description": "<p>The Workshop on HPC (High Performance Computing) Co-design in Computational Materials and Molecular Science was initiated and is led by the NOMAD Center of Excellence (www.nomad-coe.eu), and is organised by NOMAD in collaboration with the BioExcel, MAX, and TREX CoEs. </p> <p>The workshop will gather contributions from leading scientists, technologies, and SW engineers from the fields of academia, HPC centres, HW-vendors, and industry. The workshop covers a broad range of current topics, taking materials and molecular science codes as reference HPC applications and possible co-design vehicles. </p> <p>The topics to be covered are:</p> <p>(1) existing examples of HPC co-design in materials and molecular science,</p> <p>(2) co-design of general purpose and domain-specific libraries, kernels, and mini-apps, and</p> <p>(3) the perspective of hardware manufacturers, integrators, and data center owners.</p> <p>The workshop will focus in particular on, and attempt to draw conclusions about:</p> <p>(1) the relationship between algorithms and computer architectures in materials science,</p> <p>(2) the connection between parallel programming technologies and runtime systems, and</p> <p>(3) the interplay of the above layers for a wide spectrum of computer architectures, within the selected scientific domain. </p> <p>We aim to identify how scientific software developers in materials science can influence hardware manufacturers as well as middleware and system-level software developers, and vice versa. In particular, we seek to determine how co-design is employed in the development of the new HPC processors and of the related software stack, including with respect to compilers and optimized libraries, schedulers and IO, and container technologies. </p> <p>Hardware HPC vendors and integrators will share their vision on co-design, while key people from the scientific software development community will discuss the adoption of state-of-the-art technologies when porting their codes on emerging computer architectures. Consequently, the workshop will provide a rare and valuable opportunity to foster close contacts and the exchange of ideas between the scientific and technical communities.</p>", "markdown_description": "The Workshop on HPC (High Performance Computing) Co-design in Computational Materials and Molecular Science was initiated and is led by the NOMAD Center of Excellence (www.nomad-coe.eu), and is organised by NOMAD in collaboration with the BioExcel, MAX, and TREX CoEs. \n\nThe workshop will gather contributions from leading scientists, technologies, and SW engineers from the fields of academia, HPC centres, HW-vendors, and industry. The workshop covers a broad range of current topics, taking materials and molecular science codes as reference HPC applications and possible co-design vehicles. \n\nThe topics to be covered are:\n\n(1) existing examples of HPC co-design in materials and molecular science,\n\n(2) co-design of general purpose and domain-specific libraries, kernels, and mini-apps, and\n\n(3) the perspective of hardware manufacturers, integrators, and data center owners.\n\nThe workshop will focus in particular on, and attempt to draw conclusions about:\n\n(1) the relationship between algorithms and computer architectures in materials science,\n\n(2) the connection between parallel programming technologies and runtime systems, and\n\n(3) the interplay of the above layers for a wide spectrum of computer architectures, within the selected scientific domain. \n\nWe aim to identify how scientific software developers in materials science can influence hardware manufacturers as well as middleware and system-level software developers, and vice versa. In particular, we seek to determine how co-design is employed in the development of the new HPC processors and of the related software stack, including with respect to compilers and optimized libraries, schedulers and IO, and container technologies. \n\nHardware HPC vendors and integrators will share their vision on co-design, while key people from the scientific software development community will discuss the adoption of state-of-the-art technologies when porting their codes on emerging computer architectures. Consequently, the workshop will provide a rare and valuable opportunity to foster close contacts and the exchange of ideas between the scientific and technical communities.", "summary": "The Workshop on HPC (High Performance Computing) Co-design in Computational Materials and Molecular Science was initiated and is led..."}]}, {"@context": "https://schema.org", "@graph": [{"@type": "Event", "name": "Scientific Visualization with COVISE and Vistle", "url": "https://www.hlrs.de/training/2022/VIS1/", "description": "This course is targeted at researchers with basic knowledge in numerical simulation, who would like to learn how to visualize their simulation results on the desktop but also in Augmented Reality and Virtual Environments. The two-day workshop gives a short overview over scientific visualization in general, followed by a hands-on introduction to 3D desktop visualization with VISTLE  and COVISE. Participants will further learn how to build interactive 3D Models for Virtual Environments and how to set up an Augmented Reality visualization.", "eventAttendanceMode": "https://schema.org/OfflineEventAttendanceMode", "eventStatus": "https://schema.org/EventScheduled", "image": {"@type": "ImageObject", "representativeOfPage": "True", "url": "tmp_images/10aa01569f2ee9b423ac7fb24cf4c413.webp", "width": 720, "height": 486}, "doorTime": "2022-09-29T09:00:00+0200", "startDate": "2022-09-29T09:00:00+0200", "endDate": "2022-09-30T16:00:00+0200", "@id": "https://hpc-portal.eu/node/855", "isAccessibleForFree": "True", "location": {"@type": "VirtualLocation", "url": "https://www.hlrs.de/contact", "geo": {"@type": "GeoCoordinates", "latitude": "48.739485700985", "longitude": "9.0973166"}}, "language": ["English"], "sector": ["Research and Academia", "Industry", "Public Sector"], "country": ["Germany"], "projects": ["EXCELLERAT"], "level": ["Beginner", "Intermediate"], "html_description": "<p>This course is targeted at researchers with basic knowledge in numerical simulation, who would like to learn how to visualize their simulation results on the desktop but also in Augmented Reality and Virtual Environments. The two-day workshop gives a short overview over scientific visualization in general, followed by a hands-on introduction to 3D desktop visualization with <a href=\"https://services.excellerat.eu/viewcode/2\">VISTLE </a> and <a href=\"http://www.hlrs.de/covise/\">COVISE</a>. Participants will further learn how to build interactive 3D Models for Virtual Environments and how to set up an Augmented Reality visualization.</p>", "markdown_description": "This course is targeted at researchers with basic knowledge in numerical simulation, who would like to learn how to visualize their simulation results on the desktop but also in Augmented Reality and Virtual Environments. The two-day workshop gives a short overview over scientific visualization in general, followed by a hands-on introduction to 3D desktop visualization with [VISTLE ](https://services.excellerat.eu/viewcode/2) and [COVISE](http://www.hlrs.de/covise/). Participants will further learn how to build interactive 3D Models for Virtual Environments and how to set up an Augmented Reality visualization.", "summary": "This course is targeted at researchers with basic knowledge in numerical simulation, who would like to learn how to visualize their..."}]}, {"@context": "https://schema.org", "@graph": [{"@type": "Event", "name": "Training on High Performance Data Analytics and Visualisation", "url": "https://www.esiwace.eu/events/hpda-vis-training-2022", "description": "As the volumes of weather and climate data expand, it is of paramount importance for scientists to exploit techniques and solutions able to efficiently extract knowledge from these data. \n\nThis online training course aims to increase scientists\u2019 expertise on data analysis and visualisation applied to climate and weather domains, using high-performance data analytics (HPDA) and visualisation tools available from the open source market (i.e., Ophidia and ParaView). \n\nThe training covers topics from simple analytics tasks to workflows and applications (e.g., Python-based) and provides best practices and guidelines on dealing with massive scientific datasets on HPC architectures. \n\nExamples of real applications of the tools for data analytics and visualisation (i.e., Ophidia and ParaView) in the climate and weather domain will be presented. The training will include demos and hands-on sessions concerning the different tools. \n\nThis course is organised in the context of the \u201cCentre of Excellence in Simulation of Weather and Climate in Europe\u201d (ESiWACE) phase 2 project.\n\n**List of Topics** :\n\n  * Introduction to big data, scientific data management and analytics at scale\n  * Open-source High Performance Data Analytics (HPDA) tools\n  * Data Analytics workflows for eScience\n  * Introduction to data visualisation using ParaView\n  * Discussion of visualisation workflows, from post to in-situ\n\n\n\n**Audience** : The training targets the audience in the field of weather and climate research with different backgrounds, from computer to Earth system scientists. This course is open to students, young scientists and also more experienced researchers/engineers who wish to improve their data analytics and visualisation skills. Basic knowledge of Python, Linux, NetCDF data format and general aspects concerning climate/weather data is required to fully take advantage of the training.\n\n**Schedule** : The training is organised as an 8-hour online course, divided into 4 sessions, with 2 hours of work per day required for the participants. The event is scheduled for September 6-9, 2022 according to the following calendar:\n\n  * Session 1: Introduction to Ophidia, 6th September 2022, 14.30-16.30\n  * Session 2: Ophidia advanced concepts, 7th September 2022, 14.30-16.30\n  * Session 3: Introduction to ParaView, 8th September 2022, 14.30-16.30\n  * Session 4: Advanced ParaView use, 9th September 2022, 14.30-16.30\n\n\n\nEach session combines presentations about the various topics and practical tutorials/hands-on.\n\n**Participation** : Registration is required for attending the online live training sessions. The training materials (e.g., slides, instructions, notebooks, scripts, etc.) will be made available. Instructions and materials for the practical sessions will be made available beforehand to registered users.\n\n**You can register to the training from this page:https://indico.dkrz.de/event/43/**  \n**Note that the registration closes on the 2nd of September AoE.**\n\nRead our news item on the successfully completed 2021 edition of this training.", "eventAttendanceMode": "https://schema.org/OnlineEventAttendanceMode", "eventStatus": "https://schema.org/EventScheduled", "image": {"@type": "ImageObject", "representativeOfPage": "True", "url": "tmp_images/cbb16354b73ae5d813b4280f2a16cac0.webp", "width": 652, "height": 720}, "doorTime": "2022-09-06T14:30:00+0200", "startDate": "2022-09-06T14:30:00+0200", "endDate": "2022-09-09T16:30:00+0200", "@id": "https://hpc-portal.eu/node/1414", "isAccessibleForFree": "True", "location": {"@type": "VirtualLocation", "url": "https://www.esiwace.eu/events/hpda-vis-training-2022", "geo": {"@type": "GeoCoordinates", "latitude": "53.566847950422", "longitude": "9.97650715"}}, "language": ["English"], "sector": ["Research and Academia", "Industry", "Public Sector"], "country": ["Germany"], "projects": ["ESiWACE2"], "level": ["Beginner", "Intermediate", "Advanced"], "online": ["Live (synchronous)"], "html_description": "<p>As the volumes of weather and climate data expand, it is of paramount importance for scientists to exploit techniques and solutions able to efficiently extract knowledge from these data. </p> <p>This online training course aims to increase scientists\u2019 expertise on data analysis and visualisation applied to climate and weather domains, using high-performance data analytics (HPDA) and visualisation tools available from the open source market (i.e., Ophidia and ParaView). </p> <p>The training covers topics from simple analytics tasks to workflows and applications (e.g., Python-based) and provides best practices and guidelines on dealing with massive scientific datasets on HPC architectures. </p> <p>Examples of real applications of the tools for data analytics and visualisation (i.e., Ophidia and ParaView) in the climate and weather domain will be presented. The training will include demos and hands-on sessions concerning the different tools. </p> <p>This course is organised in the context of the \u201cCentre of Excellence in Simulation of Weather and Climate in Europe\u201d (ESiWACE) phase 2 project.</p> <p><strong>List of Topics</strong>:</p> <ul> <li>Introduction to big data, scientific data management and analytics at scale</li> <li>Open-source High Performance Data Analytics (HPDA) tools</li> <li>Data Analytics workflows for eScience</li> <li>Introduction to data visualisation using ParaView</li> <li>Discussion of visualisation workflows, from post to in-situ</li> </ul> <p><strong>Audience</strong>: The training targets the audience in the field of weather and climate research with different backgrounds, from computer to Earth system scientists. This course is open to students, young scientists and also more experienced researchers/engineers who wish to improve their data analytics and visualisation skills. Basic knowledge of Python, Linux, NetCDF data format and general aspects concerning climate/weather data is required to fully take advantage of the training.</p> <p><strong>Schedule</strong>: The training is organised as an 8-hour online course, divided into 4 sessions, with 2 hours of work per day required for the participants. The event is scheduled for September 6-9, 2022 according to the following calendar:</p> <ul> <li>Session 1: Introduction to Ophidia, 6th September 2022, 14.30-16.30</li> <li>Session 2: Ophidia advanced concepts, 7th September 2022, 14.30-16.30</li> <li>Session 3: Introduction to ParaView, 8th September 2022, 14.30-16.30</li> <li>Session 4: Advanced ParaView use, 9th September 2022, 14.30-16.30</li> </ul> <p>Each session combines presentations about the various topics and practical tutorials/hands-on.</p> <p><strong>Participation</strong>: Registration is required for attending the online live training sessions. The training materials (e.g., slides, instructions, notebooks, scripts, etc.) will be made available. Instructions and materials for the practical sessions will be made available beforehand to registered users.</p> <p><strong>You can register to the training from this page: <a href=\"https://indico.dkrz.de/event/43/\">https://indico.dkrz.de/event/43/</a></strong><br> <strong>Note that the registration closes on the 2nd of September AoE.</strong></p> <p> Read our <a href=\"https://www.esiwace.eu/news/news/hpda-vis-training-2021-completed\">news item</a> on the successfully completed 2021 edition of this training.</p>", "markdown_description": "As the volumes of weather and climate data expand, it is of paramount importance for scientists to exploit techniques and solutions able to efficiently extract knowledge from these data. \n\nThis online training course aims to increase scientists\u2019 expertise on data analysis and visualisation applied to climate and weather domains, using high-performance data analytics (HPDA) and visualisation tools available from the open source market (i.e., Ophidia and ParaView). \n\nThe training covers topics from simple analytics tasks to workflows and applications (e.g., Python-based) and provides best practices and guidelines on dealing with massive scientific datasets on HPC architectures. \n\nExamples of real applications of the tools for data analytics and visualisation (i.e., Ophidia and ParaView) in the climate and weather domain will be presented. The training will include demos and hands-on sessions concerning the different tools. \n\nThis course is organised in the context of the \u201cCentre of Excellence in Simulation of Weather and Climate in Europe\u201d (ESiWACE) phase 2 project.\n\n**List of Topics** :\n\n  * Introduction to big data, scientific data management and analytics at scale\n  * Open-source High Performance Data Analytics (HPDA) tools\n  * Data Analytics workflows for eScience\n  * Introduction to data visualisation using ParaView\n  * Discussion of visualisation workflows, from post to in-situ\n\n\n\n**Audience** : The training targets the audience in the field of weather and climate research with different backgrounds, from computer to Earth system scientists. This course is open to students, young scientists and also more experienced researchers/engineers who wish to improve their data analytics and visualisation skills. Basic knowledge of Python, Linux, NetCDF data format and general aspects concerning climate/weather data is required to fully take advantage of the training.\n\n**Schedule** : The training is organised as an 8-hour online course, divided into 4 sessions, with 2 hours of work per day required for the participants. The event is scheduled for September 6-9, 2022 according to the following calendar:\n\n  * Session 1: Introduction to Ophidia, 6th September 2022, 14.30-16.30\n  * Session 2: Ophidia advanced concepts, 7th September 2022, 14.30-16.30\n  * Session 3: Introduction to ParaView, 8th September 2022, 14.30-16.30\n  * Session 4: Advanced ParaView use, 9th September 2022, 14.30-16.30\n\n\n\nEach session combines presentations about the various topics and practical tutorials/hands-on.\n\n**Participation** : Registration is required for attending the online live training sessions. The training materials (e.g., slides, instructions, notebooks, scripts, etc.) will be made available. Instructions and materials for the practical sessions will be made available beforehand to registered users.\n\n**You can register to the training from this page:<https://indico.dkrz.de/event/43/>**  \n**Note that the registration closes on the 2nd of September AoE.**\n\nRead our [news item](https://www.esiwace.eu/news/news/hpda-vis-training-2021-completed) on the successfully completed 2021 edition of this training.", "summary": "As the volumes of weather and climate data expand, it is of paramount importance for scientists to exploit techniques and solutions..."}]}]