[{"@context": "https://schema.org", "@graph": [{"@type": "Event", "name": "Extended Software Development Workshop in HPC for mesoscale simulation", "url": "https://www.cecam.org/workshop-details/8", "description": "Mesoscale simulations have grown recently in importance due to their capacity of capturing molecular and atomistic effects without having to solve for a prohibitively large number of particles needed in Molecular Dynamic (MD) simulations. Different approaches, emerging from a coarse approximation to a group of atoms and molecules, allow reproducing both chemical and physical main properties as well as continuum behaviour such as the hydrodynamics of fluid flows.\n\nOne of the most common techniques is the Dissipative Particle Dynamics (DPD): an approximate, coarse-grain, mesoscale simulation method for investigating phenomena between the atomic and the continuum scale world, like flows through complex geometries, micro fluids, phase behaviours and polymer processing. It consists of an off-lattice, discrete particle method similar to MD but with replacement of a soft potential for the conservative force, a random force to simulate the Brownian motion of the particles and a drag force to balance the random force and conserve the total momentum of the system.\n\nHowever, real applications usually consist of a large number of particles and despite the coarse grain approximation, compared to MD, High Performance Computing (HPC) is often required for simulating systems of industrial and scientific interest. On the other hand, today\u2019s hardware is quickly moving towards hybrid CPU-GPU architectures. In fact, five of the top ten supercomputer are made of mixed CPU and NVidia GPU accelerators which allow to achieve hundreds of PetaFlops performance. This type of architecture is also one of the main paths toward Exascale.\n\nFew software, like DL_MESO, userMESO and LAMMPS, can currently simulate large DPD simulations. In particular, DL_MESO has recently been ported to multi-GPU architectures and runs efficiently up to 4096 GPUs. This allows investigating very large system with billions of particles within affordable computational effort. However, additional effort is required to enable the current version to cover more complex physics, like long range forces as well as achieving higher parallel computing efficiency.\n\nThe purpose of this Extended Software Development Workshop (ESDW) is to introduce students to the parallel programming of hybrid CPU-GPU systems. The intention is not only to port mesoscale solvers on GPUs, but also to expose the community to this new programming paradigm, which they can benefit from in their own fields of research. See more details about the topics covered by this ESDW under tab \u201cProgram\u201d.\n\nReferences\n\n  * Seaton M.A. et al. \u201cDL_MESO: highly scalable mesoscale simulations\u201d Molecular Simulation (39) 2013\n  * Castagna J. et al \u201cTowards Extreme Scale using Multiple GPGPUs in Dissipative Particle Dynamics Simulations\u201d, The Royal Society poster session on Numerical algorithm for high performance computational science\u201d (2019)\n  * Castagna J. et al. \u201cTowards extreme scale dissipative particle dynamics simulations using multiple GPGPUs\u201d, Computer Physics Communications (2020) 107159, https://doi.org/10.1016/j.cpc.2020.107159", "eventAttendanceMode": "https://schema.org/OnlineEventAttendanceMode", "eventStatus": "https://schema.org/EventScheduled", "image": {"@type": "ImageObject", "representativeOfPage": "True", "url": "images/FocusCoE_placeholder.webp", "width": 720, "height": 231}, "doorTime": "2021-01-18T09:00:00+0100", "startDate": "2021-01-18T09:00:00+0100", "endDate": "2021-01-22T17:00:00+0100", "@id": "https://hpc-portal.eu/node/971", "isAccessibleForFree": "True", "location": {"@type": "VirtualLocation", "url": "https://www.cecam.org/workshop-details/8", "geo": {"@type": "GeoCoordinates", "latitude": "53.343521167406", "longitude": "-2.6407369"}}, "language": ["English"], "sector": ["Research and Academia"], "country": ["United Kingdom"], "projects": ["E-CAM"], "level": ["Beginner", "Intermediate"], "online": ["Live (synchronous)"], "html_description": "<p>Mesoscale simulations have grown recently in importance due to their capacity of capturing molecular and atomistic effects without having to solve for a prohibitively large number of particles needed in Molecular Dynamic (MD) simulations. Different approaches, emerging from a coarse approximation to a group of atoms and molecules, allow reproducing both chemical and physical main properties as well as continuum behaviour such as the hydrodynamics of fluid flows.</p> <p>One of the most common techniques is the Dissipative Particle Dynamics (DPD): an approximate, coarse-grain, mesoscale simulation method for investigating phenomena between the atomic and the continuum scale world, like flows through complex geometries, micro fluids, phase behaviours and polymer processing. It consists of an off-lattice, discrete particle method similar to MD but with replacement of a soft potential for the conservative force, a random force to simulate the Brownian motion of the particles and a drag force to balance the random force and conserve the total momentum of the system.</p> <p>However, real applications usually consist of a large number of particles and despite the coarse grain approximation, compared to MD, High Performance Computing (HPC) is often required for simulating systems of industrial and scientific interest. On the other hand, today\u2019s hardware is quickly moving towards hybrid CPU-GPU architectures. In fact, five of the top ten supercomputer are made of mixed CPU and NVidia GPU accelerators which allow to achieve hundreds of PetaFlops performance. This type of architecture is also one of the main paths toward Exascale.</p> <p>Few software, like DL_MESO, userMESO and LAMMPS, can currently simulate large DPD simulations. In particular, DL_MESO has recently been ported to multi-GPU architectures and runs efficiently up to 4096 GPUs. This allows investigating very large system with billions of particles within affordable computational effort. However, additional effort is required to enable the current version to cover more complex physics, like long range forces as well as achieving higher parallel computing efficiency.</p> <p>The purpose of this Extended Software Development Workshop (ESDW) is to introduce students to the parallel programming of hybrid CPU-GPU systems. The intention is not only to port mesoscale solvers on GPUs, but also to expose the community to this new programming paradigm, which they can benefit from in their own fields of research. See more details about the topics covered by this ESDW under tab \u201cProgram\u201d.</p> <p>References</p> <ul> <li>Seaton M.A. et al. \u201cDL_MESO: highly scalable mesoscale simulations\u201d Molecular Simulation (39) 2013</li> <li>Castagna J. et al \u201cTowards Extreme Scale using Multiple GPGPUs in Dissipative Particle Dynamics Simulations\u201d, The Royal Society poster session on Numerical algorithm for high performance computational science\u201d (2019)</li> <li>Castagna J. et al. \u201cTowards extreme scale dissipative particle dynamics simulations using multiple GPGPUs\u201d, Computer Physics Communications (2020) 107159, <a href=\"https://doi.org/10.1016/j.cpc.2020.107159\">https://doi.org/10.1016/j.cpc.2020.107159</a></li> </ul>", "markdown_description": "Mesoscale simulations have grown recently in importance due to their capacity of capturing molecular and atomistic effects without having to solve for a prohibitively large number of particles needed in Molecular Dynamic (MD) simulations. Different approaches, emerging from a coarse approximation to a group of atoms and molecules, allow reproducing both chemical and physical main properties as well as continuum behaviour such as the hydrodynamics of fluid flows.\n\nOne of the most common techniques is the Dissipative Particle Dynamics (DPD): an approximate, coarse-grain, mesoscale simulation method for investigating phenomena between the atomic and the continuum scale world, like flows through complex geometries, micro fluids, phase behaviours and polymer processing. It consists of an off-lattice, discrete particle method similar to MD but with replacement of a soft potential for the conservative force, a random force to simulate the Brownian motion of the particles and a drag force to balance the random force and conserve the total momentum of the system.\n\nHowever, real applications usually consist of a large number of particles and despite the coarse grain approximation, compared to MD, High Performance Computing (HPC) is often required for simulating systems of industrial and scientific interest. On the other hand, today\u2019s hardware is quickly moving towards hybrid CPU-GPU architectures. In fact, five of the top ten supercomputer are made of mixed CPU and NVidia GPU accelerators which allow to achieve hundreds of PetaFlops performance. This type of architecture is also one of the main paths toward Exascale.\n\nFew software, like DL_MESO, userMESO and LAMMPS, can currently simulate large DPD simulations. In particular, DL_MESO has recently been ported to multi-GPU architectures and runs efficiently up to 4096 GPUs. This allows investigating very large system with billions of particles within affordable computational effort. However, additional effort is required to enable the current version to cover more complex physics, like long range forces as well as achieving higher parallel computing efficiency.\n\nThe purpose of this Extended Software Development Workshop (ESDW) is to introduce students to the parallel programming of hybrid CPU-GPU systems. The intention is not only to port mesoscale solvers on GPUs, but also to expose the community to this new programming paradigm, which they can benefit from in their own fields of research. See more details about the topics covered by this ESDW under tab \u201cProgram\u201d.\n\nReferences\n\n  * Seaton M.A. et al. \u201cDL_MESO: highly scalable mesoscale simulations\u201d Molecular Simulation (39) 2013\n  * Castagna J. et al \u201cTowards Extreme Scale using Multiple GPGPUs in Dissipative Particle Dynamics Simulations\u201d, The Royal Society poster session on Numerical algorithm for high performance computational science\u201d (2019)\n  * Castagna J. et al. \u201cTowards extreme scale dissipative particle dynamics simulations using multiple GPGPUs\u201d, Computer Physics Communications (2020) 107159, <https://doi.org/10.1016/j.cpc.2020.107159>", "summary": "Mesoscale simulations have grown recently in importance due to their capacity of capturing molecular and atomistic effects without..."}]}, {"@context": "https://schema.org", "@graph": [{"@type": "Event", "name": "AiiDA Virtual Tutorial", "url": "http://www.max-centre.eu/news-events/aiida-virtual-tutorial", "description": "The goal of this 4 day-tutorial is to help students and researchers from the field of computational materials science get started with writing reproducible workflows. They will be introduced by experts in the field (including the developers of the code) to the use of AiiDA, a state-of-the-art framework for provenance tracking and workflow management designed to support high-throughput research, and will gain in-depth hands-on experience using a tool that they can directly apply to their own research. Participation both from academia and from industry is encouraged.\n\nThe AiiDA framework is a tool for workflow management and provenance tracking, which is backed by a significant community of users and developers, and has interfaces to more than 30 materials science codes (see plugin registry), including (among others) to the ab initio codes Quantum ESPRESSO, VASP, cp2k, Castep, Siesta, Fleur, Crystal, NWChem, Wannier90, and Yambo. AiiDA\u2019s permissive open source license (MIT) enables participants to use it both in academic and commercial settings. By virtue of its general design and flexible plugin system, AiiDA is easily extended to new codes and new use cases.\n\nTalks will be pre-recorded and made available to participants before the event, and hands-on tutorials will be held _via_ Zoom. In order to avoid losing time on installation issues, participants will have the option to connect to virtual machines preconfigured with AiiDA (or to come with AiiDA already installed on their laptop via the Quantum Mobile virtual machine).\n\nThe event will mostly focus on in-depth tutorials on using AiiDA and on writing workflows. It will also include some talks on how AiiDA has been already used in production, given by the organisers and the core developers of AiiDA; on advanced aspects of workflow management; on designing and writing new AiiDA plugins; and on research data management (RDM) and how to write data management plans (DMPs), especially when using AiiDA and the Materials Cloud.\n\n**Speakers & organisers**\n\nThe tutorial is organised by **Chris Sewell (EPFL, CH), Marnik Bercx (EPFL, CH)** and **Giovanni Pizzi (EPFL, CH).**\n\nTutorial lectures and assistance during hands-on session will be provided by the organisers and a team of core AiiDA developers: Sebastiaan Huber, Leopold Talirz, Yakutovich Aliaksandr, Casper Andersen and Francisco Ramirez.\n\nFor general information concerning the tutorial you can contact Chris (christopher.sewell@epfl.ch) or Marnik (marnik.bercx@epfl.ch).\n\nMore info here", "eventAttendanceMode": "https://schema.org/OnlineEventAttendanceMode", "eventStatus": "https://schema.org/EventScheduled", "image": {"@type": "ImageObject", "representativeOfPage": "True", "url": "images/FocusCoE_placeholder.webp", "width": 720, "height": 231}, "doorTime": "2020-07-07T09:00:00+0200", "startDate": "2020-07-07T09:00:00+0200", "endDate": "2020-07-10T17:00:00+0200", "@id": "https://hpc-portal.eu/node/1375", "isAccessibleForFree": "True", "location": {"@type": "VirtualLocation", "url": "http://www.max-centre.eu/news-events/aiida-virtual-tutorial", "geo": {"@type": "GeoCoordinates", "latitude": "44.6319012", "longitude": "10.9453679"}}, "language": ["English"], "sector": ["Research and Academia", "Industry"], "country": ["Italy"], "projects": ["MaX"], "level": ["Beginner", "Intermediate"], "online": ["Live (synchronous)"], "html_description": "<p>The goal of this 4 day-tutorial is to help students and researchers from the field of computational materials science get started with writing reproducible workflows. They will be introduced by experts in the field (including the developers of the code) to the use of AiiDA, a state-of-the-art framework for provenance tracking and workflow management designed to support high-throughput research, and will gain in-depth hands-on experience using a tool that they can directly apply to their own research. Participation both from academia and from industry is encouraged.</p> <p>The AiiDA framework is a tool for workflow management and provenance tracking, which is backed by a significant community of users and developers, and has interfaces to more than 30 materials science codes (see <a href=\"http://aiidateam.github.io/aiida-registry\">plugin registry</a>), including (among others) to the ab initio codes Quantum ESPRESSO, VASP, cp2k, Castep, Siesta, Fleur, Crystal, NWChem, Wannier90, and Yambo. AiiDA\u2019s permissive open source license (MIT) enables participants to use it both in academic and commercial settings. By virtue of its general design and flexible plugin system, AiiDA is easily extended to new codes and new use cases.</p> <p>Talks will be pre-recorded and made available to participants before the event, and hands-on tutorials will be held <em>via</em> <a href=\"https://zoom.us/\">Zoom</a>. In order to avoid losing time on installation issues, participants will have the option to connect to virtual machines preconfigured with AiiDA (or to come with AiiDA already installed on their laptop via the <a href=\"https://www.materialscloud.org/work/quantum-mobile\">Quantum Mobile virtual machine</a>).</p> <p>The event will mostly focus on in-depth tutorials on using AiiDA and on writing workflows. It will also include some talks on how AiiDA has been already used in production, given by the organisers and the core developers of AiiDA; on advanced aspects of workflow management; on designing and writing new AiiDA plugins; and on research data management (RDM) and how to write data management plans (DMPs), especially when using AiiDA and the <a href=\"https://www.materialscloud.org/\">Materials Cloud</a>.</p> <p><strong>Speakers &amp; organisers</strong></p> <p>The tutorial is organised by <strong>Chris Sewell (EPFL, CH), Marnik Bercx (EPFL, CH) </strong>and<strong> Giovanni Pizzi (EPFL, CH).</strong></p> <p>Tutorial lectures and assistance during hands-on session will be provided by the organisers and a team of core AiiDA developers: Sebastiaan Huber, Leopold Talirz, Yakutovich Aliaksandr, Casper Andersen and Francisco Ramirez.</p> <p>For general information concerning the tutorial you can contact Chris (<a href=\"mailto:christopher.sewell@epfl.ch\">christopher.sewell@epfl.ch</a>) or Marnik (<a href=\"mailto:marnik.bercx@epfl.ch\">marnik.bercx@epfl.ch</a>).</p> <p>More info <a href=\"http://www.aiida.net/aiida-virtual-tutorial-july-2020/\">here</a></p>", "markdown_description": "The goal of this 4 day-tutorial is to help students and researchers from the field of computational materials science get started with writing reproducible workflows. They will be introduced by experts in the field (including the developers of the code) to the use of AiiDA, a state-of-the-art framework for provenance tracking and workflow management designed to support high-throughput research, and will gain in-depth hands-on experience using a tool that they can directly apply to their own research. Participation both from academia and from industry is encouraged.\n\nThe AiiDA framework is a tool for workflow management and provenance tracking, which is backed by a significant community of users and developers, and has interfaces to more than 30 materials science codes (see [plugin registry](http://aiidateam.github.io/aiida-registry)), including (among others) to the ab initio codes Quantum ESPRESSO, VASP, cp2k, Castep, Siesta, Fleur, Crystal, NWChem, Wannier90, and Yambo. AiiDA\u2019s permissive open source license (MIT) enables participants to use it both in academic and commercial settings. By virtue of its general design and flexible plugin system, AiiDA is easily extended to new codes and new use cases.\n\nTalks will be pre-recorded and made available to participants before the event, and hands-on tutorials will be held _via_ [Zoom](https://zoom.us/). In order to avoid losing time on installation issues, participants will have the option to connect to virtual machines preconfigured with AiiDA (or to come with AiiDA already installed on their laptop via the [Quantum Mobile virtual machine](https://www.materialscloud.org/work/quantum-mobile)).\n\nThe event will mostly focus on in-depth tutorials on using AiiDA and on writing workflows. It will also include some talks on how AiiDA has been already used in production, given by the organisers and the core developers of AiiDA; on advanced aspects of workflow management; on designing and writing new AiiDA plugins; and on research data management (RDM) and how to write data management plans (DMPs), especially when using AiiDA and the [Materials Cloud](https://www.materialscloud.org/).\n\n**Speakers & organisers**\n\nThe tutorial is organised by **Chris Sewell (EPFL, CH), Marnik Bercx (EPFL, CH)** and **Giovanni Pizzi (EPFL, CH).**\n\nTutorial lectures and assistance during hands-on session will be provided by the organisers and a team of core AiiDA developers: Sebastiaan Huber, Leopold Talirz, Yakutovich Aliaksandr, Casper Andersen and Francisco Ramirez.\n\nFor general information concerning the tutorial you can contact Chris ([christopher.sewell@epfl.ch](mailto:christopher.sewell@epfl.ch)) or Marnik ([marnik.bercx@epfl.ch](mailto:marnik.bercx@epfl.ch)).\n\nMore info [here](http://www.aiida.net/aiida-virtual-tutorial-july-2020/)", "summary": "The goal of this 4 day-tutorial is to help students and researchers from the field of computational materials science get started..."}]}, {"@context": "https://schema.org", "@graph": [{"@type": "Event", "name": "Integration of ESL modules into electronic-structure codes", "url": "http://www.max-centre.eu/news-events/integration-esl-modules-electronic-structure-codes-0", "description": "The evolutionary pressure on electronic structure software development is greatly increasing, due to the emergence of new paradigms, new kinds of users, new processes, and new tools. Electronic structure software complexity is consequently also increasing, requiring a larger effort on code maintenance. Developers of large electronic structure codes are trying to relieve some complexity by transitioning standardized algorithms into separate libraries [BigDFT-PSolver, ELPA, ELSI, LibXC, LibGridXC, etc.]. This paradigm shift requires library developers to have a hybrid developer profile where the scientific and computational skill set becomes equally important. These topics have been extensively and publicly discussed between developers of various projects including ABINIT, ASE, ATK, BigDFT, CASTEP, FHI-aims, GPAW, Octopus, Quantum Espresso, SIESTA, and SPR-KKR.\n\nHigh-quality standardized libraries are not only a highly challenging effort lying at the hands of the library developers, they also open possibilities for codes to take advantage of a standard way to access commonly used algorithms. Integration of these libraries, however, requires a significant initial effort that is often sacrificed for new developments that often not even reach the mainstream branch of the code. Additionally, there are multiple challenges in adopting new libraries which have their roots in a variety of issues: installation, data structures, physical units and parallelism - all of which are code-dependent. On the other hand, adoption of common libraries ensures the immediate propagation of improvements within the respective library\u2019s field of research and ensures codes are up-to-date with much less effort [LibXC]. Indeed, well-established libraries can have a huge impact on multiple scientific communities at once [PETSc].\n\nIn the Electronic Structure community, two issues are emerging. Libraries are being developed [esl, esl-gitlab] but require an ongoing commitment from the community with respect to sharing the maintenance and development effort. Secondly, existing codes will benefit from libraries by adopting their use. Both issues are mainly governed by the exposure of the libraries and the availability of library core developers, which are typically researchers pressured by publication deliverables and fund-raising burdens. They are thus not able to commit a large fraction of their time to software development.\n\nAn effort to allow code developers to make use of, and develop, shared components is needed. This requires an efficient coordination between various elements:\n\nA common and consistent code development infrastructure/education in terms of compilation, installation, testing and documentation.  \n\\- How to use and integrate already published libraries into existing projects.  \n\\- Creating long-lasting synergies between developers to reach a \u201ccritical mass\u201d of component contributors.  \n\\- Relevant quality metrics (\"TRLs\" and \u201cSRLs\u201d), to provide businesses with useful information .\n\nThis is what the Electronic Structure Library (ESL)[esl, esl-gitlab] has been doing since 2014, with a wiki, a data-exchange standard, refactoring code of global interest into integrated modules, and regularly organizing workshops, within a wider movement lead by the European eXtreme Data and Computing Initiative [exdci].\n\nReferences\n\n[BigDFT-PSolver] http://bigdft.org/Wiki/index.php?title=The_Solver_Package  \n[ELPA] https://gitlab.mpcdf.mgp.de/elpa/elpa  \n[ELSI] http://elsi-interchange.org  \n[LibXC] http://www.tddft.org/programs/libxc/  \n[LibGridXC] https://launchpad.net/libgridxc  \n[PETSc] https://www.mcs.anl.gov/petsc/  \n[esl] http://esl.cecam.org/  \n[esl-gitlab] http://gitlab.e-cam2020.eu/esl  \n[exdci] https://exdci.eu/newsroom/press-releases/exdci-towards-common-hpc-strate...", "eventAttendanceMode": "https://schema.org/OfflineEventAttendanceMode", "eventStatus": "https://schema.org/EventScheduled", "image": {"@type": "ImageObject", "representativeOfPage": "True", "url": "images/FocusCoE_placeholder.webp", "width": 720, "height": 231}, "doorTime": "2020-02-17T09:00:00+0100", "startDate": "2020-02-17T09:00:00+0100", "endDate": "2020-02-18T17:00:00+0100", "@id": "https://hpc-portal.eu/node/1376", "isAccessibleForFree": "True", "location": {"@type": "VirtualLocation", "url": "http://www.max-centre.eu/news-events/integration-esl-modules-electronic-structure-codes-0", "geo": {"@type": "GeoCoordinates", "latitude": "46.5201508", "longitude": "6.5722361"}}, "language": ["English"], "sector": ["Research and Academia", "Industry"], "country": ["Switzerland"], "projects": ["MaX"], "level": ["Beginner", "Intermediate", "Advanced"], "html_description": "<p>The evolutionary pressure on electronic structure software development is greatly increasing, due to the emergence of new paradigms, new kinds of users, new processes, and new tools. Electronic structure software complexity is consequently also increasing, requiring a larger effort on code maintenance. Developers of large electronic structure codes are trying to relieve some complexity by transitioning standardized algorithms into separate libraries [BigDFT-PSolver, ELPA, ELSI, LibXC, LibGridXC, etc.]. This paradigm shift requires library developers to have a hybrid developer profile where the scientific and computational skill set becomes equally important. These topics have been extensively and publicly discussed between developers of various projects including ABINIT, ASE, ATK, BigDFT, CASTEP, FHI-aims, GPAW, Octopus, Quantum Espresso, SIESTA, and SPR-KKR.</p> <p>High-quality standardized libraries are not only a highly challenging effort lying at the hands of the library developers, they also open possibilities for codes to take advantage of a standard way to access commonly used algorithms. Integration of these libraries, however, requires a significant initial effort that is often sacrificed for new developments that often not even reach the mainstream branch of the code. Additionally, there are multiple challenges in adopting new libraries which have their roots in a variety of issues: installation, data structures, physical units and parallelism - all of which are code-dependent. On the other hand, adoption of common libraries ensures the immediate propagation of improvements within the respective library\u2019s field of research and ensures codes are up-to-date with much less effort [LibXC]. Indeed, well-established libraries can have a huge impact on multiple scientific communities at once [PETSc].</p> <p>In the Electronic Structure community, two issues are emerging. Libraries are being developed [esl, esl-gitlab] but require an ongoing commitment from the community with respect to sharing the maintenance and development effort. Secondly, existing codes will benefit from libraries by adopting their use. Both issues are mainly governed by the exposure of the libraries and the availability of library core developers, which are typically researchers pressured by publication deliverables and fund-raising burdens. They are thus not able to commit a large fraction of their time to software development.</p> <p>An effort to allow code developers to make use of, and develop, shared components is needed. This requires an efficient coordination between various elements:</p> <p>A common and consistent code development infrastructure/education in terms of compilation, installation, testing and documentation.<br> - How to use and integrate already published libraries into existing projects.<br> - Creating long-lasting synergies between developers to reach a \u201ccritical mass\u201d of component contributors.<br> - Relevant quality metrics (\"TRLs\" and \u201cSRLs\u201d), to provide businesses with useful information .</p> <p>This is what the Electronic Structure Library (ESL)[esl, esl-gitlab] has been doing since 2014, with a wiki, a data-exchange standard, refactoring code of global interest into integrated modules, and regularly organizing workshops, within a wider movement lead by the European eXtreme Data and Computing Initiative [exdci].</p> <p>References</p> <p>[BigDFT-PSolver] <a href=\"http://bigdft.org/Wiki/index.php?title=The_Solver_Package\">http://bigdft.org/Wiki/index.php?title=The_Solver_Package</a><br> [ELPA] <a href=\"https://gitlab.mpcdf.mgp.de/elpa/elpa\">https://gitlab.mpcdf.mgp.de/elpa/elpa</a><br> [ELSI] <a href=\"http://elsi-interchange.org/\">http://elsi-interchange.org</a><br> [LibXC] <a href=\"http://www.tddft.org/programs/libxc/\">http://www.tddft.org/programs/libxc/</a><br> [LibGridXC] <a href=\"https://launchpad.net/libgridxc\">https://launchpad.net/libgridxc</a><br> [PETSc] <a href=\"https://www.mcs.anl.gov/petsc/\">https://www.mcs.anl.gov/petsc/</a><br> [esl] <a href=\"http://esl.cecam.org/\">http://esl.cecam.org/</a><br> [esl-gitlab] <a href=\"http://gitlab.e-cam2020.eu/esl\">http://gitlab.e-cam2020.eu/esl</a><br> [exdci] <a href=\"https://exdci.eu/newsroom/press-releases/exdci-towards-common-hpc-strategy-europe\">https://exdci.eu/newsroom/press-releases/exdci-towards-common-hpc-strate...</a></p>", "markdown_description": "The evolutionary pressure on electronic structure software development is greatly increasing, due to the emergence of new paradigms, new kinds of users, new processes, and new tools. Electronic structure software complexity is consequently also increasing, requiring a larger effort on code maintenance. Developers of large electronic structure codes are trying to relieve some complexity by transitioning standardized algorithms into separate libraries [BigDFT-PSolver, ELPA, ELSI, LibXC, LibGridXC, etc.]. This paradigm shift requires library developers to have a hybrid developer profile where the scientific and computational skill set becomes equally important. These topics have been extensively and publicly discussed between developers of various projects including ABINIT, ASE, ATK, BigDFT, CASTEP, FHI-aims, GPAW, Octopus, Quantum Espresso, SIESTA, and SPR-KKR.\n\nHigh-quality standardized libraries are not only a highly challenging effort lying at the hands of the library developers, they also open possibilities for codes to take advantage of a standard way to access commonly used algorithms. Integration of these libraries, however, requires a significant initial effort that is often sacrificed for new developments that often not even reach the mainstream branch of the code. Additionally, there are multiple challenges in adopting new libraries which have their roots in a variety of issues: installation, data structures, physical units and parallelism - all of which are code-dependent. On the other hand, adoption of common libraries ensures the immediate propagation of improvements within the respective library\u2019s field of research and ensures codes are up-to-date with much less effort [LibXC]. Indeed, well-established libraries can have a huge impact on multiple scientific communities at once [PETSc].\n\nIn the Electronic Structure community, two issues are emerging. Libraries are being developed [esl, esl-gitlab] but require an ongoing commitment from the community with respect to sharing the maintenance and development effort. Secondly, existing codes will benefit from libraries by adopting their use. Both issues are mainly governed by the exposure of the libraries and the availability of library core developers, which are typically researchers pressured by publication deliverables and fund-raising burdens. They are thus not able to commit a large fraction of their time to software development.\n\nAn effort to allow code developers to make use of, and develop, shared components is needed. This requires an efficient coordination between various elements:\n\nA common and consistent code development infrastructure/education in terms of compilation, installation, testing and documentation.  \n\\- How to use and integrate already published libraries into existing projects.  \n\\- Creating long-lasting synergies between developers to reach a \u201ccritical mass\u201d of component contributors.  \n\\- Relevant quality metrics (\"TRLs\" and \u201cSRLs\u201d), to provide businesses with useful information .\n\nThis is what the Electronic Structure Library (ESL)[esl, esl-gitlab] has been doing since 2014, with a wiki, a data-exchange standard, refactoring code of global interest into integrated modules, and regularly organizing workshops, within a wider movement lead by the European eXtreme Data and Computing Initiative [exdci].\n\nReferences\n\n[BigDFT-PSolver] <http://bigdft.org/Wiki/index.php?title=The_Solver_Package>  \n[ELPA] <https://gitlab.mpcdf.mgp.de/elpa/elpa>  \n[ELSI] [http://elsi-interchange.org](http://elsi-interchange.org/)  \n[LibXC] <http://www.tddft.org/programs/libxc/>  \n[LibGridXC] <https://launchpad.net/libgridxc>  \n[PETSc] <https://www.mcs.anl.gov/petsc/>  \n[esl] <http://esl.cecam.org/>  \n[esl-gitlab] <http://gitlab.e-cam2020.eu/esl>  \n[exdci] [https://exdci.eu/newsroom/press-releases/exdci-towards-common-hpc-strate...](https://exdci.eu/newsroom/press-releases/exdci-towards-common-hpc-strategy-europe)", "summary": "The evolutionary pressure on electronic structure software development is greatly increasing, due to the emergence of new paradigms,..."}]}]