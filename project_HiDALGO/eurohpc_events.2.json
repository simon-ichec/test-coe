[{"@context": "https://schema.org", "@graph": [{"@type": "Event", "name": "Reproducible Software Environments & Benchmarks with Ansible and Spack: HiDALGO approach", "url": "https://moodle.hidalgo-project.eu/course/view.php?id=11", "description": "A talk will be given by Sergiy Gogolenko at HLRS (HiDALGO partner) on simplifying user software installation on versatile clusters/testbeds, as well as creating reproducible software environments and benchmarks with Spack and Ansible for HiDALGO and HLRS-SANE teams.\n\nAbstract:  \nIn recent decades, there is a tendency to pay solid attention to reproducibility of experiments in science. In many cases, reproducibility becomes one of the corner-stone measures (or even pre-requisite for publication) of the high quality research. In terms of HPC, reproducibility of benchmarks presumes exhaustive reports of the hardware and software setup, as well as an easy and consistent way to replicate the software environment in use.  \nUnfortunately, the users of HPC clusters and testbeds face with a number of obstacles on the way to prepare reproducible software environments. In particular, each data center provides its own subset of pre-installed software and has a set of specific policies and restrictions (like lack of access to internet). Moreover, in order to reach better performance, the end-user usually must install the software from sources watching all its dependencies, which demands an unnecessarily high level of technical expertise. As a results, installation often becomes a tedious time-consuming process discouraging people from taking care of software reproducibility particularly and from HPC generally.  \nSpack is a HPC-oriented package manager, which solves most of the above-mentioned problems if configured correctly, while Ansible addresses the issue of deploying and configuring Spack with off-line mirrors for the end-users. In addition, Ansible and Spack feature deep integration of YAML and JSON formats along with a high extensibility via a wide range of builtin and external modules. It makes these tools a perfect combination not only for automated fully-reproducible software installation, but also for documenting hardware and software configurations along with the installation process uniformly in a human readable format easy to post-process.  \nThe purpose of this talk is largely to teach basics of configuring and using Spack for the end-users of HPC systems, as well as to introduce an Ansible+Spack solution which we use for automated installation of the same software on a variety of clusters.  \nTentative agenda:  \n\\- Introduction to Spack and Ansible (5min)  \n\\- Spack from user prospective: basic usage (10min)  \n\\- Configuring Spack (15 min)  \n\\- Deployment of Spack on versatile hardware with Ansible (10min)  \n\\- Reproducible benchmarks and their reporting with Ansible (10min)  \n\\- Reproducible benchmarks and their reporting with Ansible (10min)  \n\\- Q&A (10min)", "eventAttendanceMode": "https://schema.org/OnlineEventAttendanceMode", "eventStatus": "https://schema.org/EventScheduled", "image": {"@type": "ImageObject", "representativeOfPage": "True", "url": "tmp_images/7bd67ca75e1c454c1f60272678f6b66c.webp", "width": 720, "height": 446}, "doorTime": "2021-04-14T14:00:00+0200", "startDate": "2021-04-14T14:00:00+0200", "endDate": "2021-04-14T16:00:00+0200", "@id": "https://hpc-portal.eu/node/868", "isAccessibleForFree": "True", "location": {"@type": "VirtualLocation", "url": "https://moodle.hidalgo-project.eu/course/view.php?id=11", "geo": {"@type": "GeoCoordinates", "latitude": "48.739485700985", "longitude": "9.0973166"}}, "language": ["English"], "sector": ["Research and Academia", "Industry", "Public Sector"], "country": ["Germany"], "projects": ["HiDALGO"], "level": ["Beginner", "Other"], "online": ["Live (synchronous)"], "html_description": "<p>A talk will be given by Sergiy Gogolenko at HLRS (HiDALGO partner) on simplifying user software installation on versatile clusters/testbeds, as well as creating reproducible software environments and benchmarks with Spack and Ansible for HiDALGO and HLRS-SANE teams.</p> <p>Abstract:<br>  In recent decades, there is a tendency to pay solid attention to reproducibility of experiments in science. In many cases, reproducibility becomes one of the corner-stone measures (or even pre-requisite for publication) of the high quality research. In terms of HPC, reproducibility of benchmarks presumes exhaustive reports of the hardware and software setup, as well as an easy and consistent way to replicate the software environment in use.<br>  Unfortunately, the users of HPC clusters and testbeds face with a number of obstacles on the way to prepare reproducible software environments. In particular, each data center provides its own subset of pre-installed software and has a set of specific policies and restrictions (like lack of access to internet). Moreover, in order to reach better performance, the end-user usually must install the software from sources watching all its dependencies, which demands an unnecessarily high level of technical expertise. As a results, installation often becomes a tedious time-consuming process discouraging people from taking care of software reproducibility particularly and from HPC generally.<br>  Spack is a HPC-oriented package manager, which solves most of the above-mentioned problems if configured correctly, while Ansible addresses the issue of deploying and configuring Spack with off-line mirrors for the end-users. In addition, Ansible and Spack feature deep integration of YAML and JSON formats along with a high extensibility via a wide range of builtin and external modules. It makes these tools a perfect combination not only for automated fully-reproducible software installation, but also for documenting hardware and software configurations along with the installation process uniformly in a human readable format easy to post-process.<br>  The purpose of this talk is largely to teach basics of configuring and using Spack for the end-users of HPC systems, as well as to introduce an Ansible+Spack solution which we use for automated installation of the same software on a variety of clusters.<br>  Tentative agenda:<br>  - Introduction to Spack and Ansible (5min)<br> - Spack from user prospective: basic usage (10min)<br> - Configuring Spack (15 min)<br> - Deployment of Spack on versatile hardware with Ansible (10min)<br> - Reproducible benchmarks and their reporting with Ansible (10min)<br> - Reproducible benchmarks and their reporting with Ansible (10min)<br> - Q&amp;A (10min)</p>", "markdown_description": "A talk will be given by Sergiy Gogolenko at HLRS (HiDALGO partner) on simplifying user software installation on versatile clusters/testbeds, as well as creating reproducible software environments and benchmarks with Spack and Ansible for HiDALGO and HLRS-SANE teams.\n\nAbstract:  \nIn recent decades, there is a tendency to pay solid attention to reproducibility of experiments in science. In many cases, reproducibility becomes one of the corner-stone measures (or even pre-requisite for publication) of the high quality research. In terms of HPC, reproducibility of benchmarks presumes exhaustive reports of the hardware and software setup, as well as an easy and consistent way to replicate the software environment in use.  \nUnfortunately, the users of HPC clusters and testbeds face with a number of obstacles on the way to prepare reproducible software environments. In particular, each data center provides its own subset of pre-installed software and has a set of specific policies and restrictions (like lack of access to internet). Moreover, in order to reach better performance, the end-user usually must install the software from sources watching all its dependencies, which demands an unnecessarily high level of technical expertise. As a results, installation often becomes a tedious time-consuming process discouraging people from taking care of software reproducibility particularly and from HPC generally.  \nSpack is a HPC-oriented package manager, which solves most of the above-mentioned problems if configured correctly, while Ansible addresses the issue of deploying and configuring Spack with off-line mirrors for the end-users. In addition, Ansible and Spack feature deep integration of YAML and JSON formats along with a high extensibility via a wide range of builtin and external modules. It makes these tools a perfect combination not only for automated fully-reproducible software installation, but also for documenting hardware and software configurations along with the installation process uniformly in a human readable format easy to post-process.  \nThe purpose of this talk is largely to teach basics of configuring and using Spack for the end-users of HPC systems, as well as to introduce an Ansible+Spack solution which we use for automated installation of the same software on a variety of clusters.  \nTentative agenda:  \n\\- Introduction to Spack and Ansible (5min)  \n\\- Spack from user prospective: basic usage (10min)  \n\\- Configuring Spack (15 min)  \n\\- Deployment of Spack on versatile hardware with Ansible (10min)  \n\\- Reproducible benchmarks and their reporting with Ansible (10min)  \n\\- Reproducible benchmarks and their reporting with Ansible (10min)  \n\\- Q&A (10min)", "summary": "A talk will be given by Sergiy Gogolenko at HLRS (HiDALGO partner) on simplifying user software installation on versatile..."}]}, {"@context": "https://schema.org", "@graph": [{"@type": "Event", "name": "Iterative Solvers for Linear Systems @ HLRS", "url": "https://www.hlrs.de/training/2021/ITER-S/", "description": "The focus of the course is on modern iterative solvers for large linear systems of equations. Thereby, beside classical schemes and fundamentals of multigrid techniques different modern Krylov subspace methods (CG, GMRES, BiCGSTAB ...) as well as highly efficient preconditioning techniques are presented in the context of real life applications. Hands-on sessions (MATLAB and GNU Octave respectively) will allow users to immediately test and understand the basic constructs of iterative solvers. This course provides scientific training in Computational Science, and in addition, the scientific exchange of the participants among themselves. It is organized by HLRS, IAG, and Uni. Kassel.\n\nThe guest lecture on Day 2 is offered in collaboration with **HiDALGO**, the EU Centre of Excellence for Global Challenges. The method exposed is used in the HiDALGO **Social Network Pilot**.", "eventAttendanceMode": "https://schema.org/OnlineEventAttendanceMode", "eventStatus": "https://schema.org/EventScheduled", "image": {"@type": "ImageObject", "representativeOfPage": "True", "url": "images/FocusCoE_placeholder.webp", "width": 720, "height": 231}, "doorTime": "2021-03-08T09:00:00+0100", "startDate": "2021-03-08T09:00:00+0100", "endDate": "2021-03-10T16:00:00+0100", "@id": "https://hpc-portal.eu/node/867", "isAccessibleForFree": "True", "location": {"@type": "VirtualLocation", "url": "https://www.hlrs.de/training/2021/ITER-S/", "geo": {"@type": "GeoCoordinates", "latitude": "48.739485700985", "longitude": "9.0973166"}}, "language": ["English"], "sector": ["Research and Academia", "Industry", "Public Sector"], "country": ["Germany"], "projects": ["HiDALGO"], "level": ["Beginner", "Intermediate", "Advanced"], "online": ["Live (synchronous)"], "html_description": "<p>The focus of the course is on modern iterative solvers for large linear systems of equations. Thereby, beside classical schemes and fundamentals of multigrid techniques different modern Krylov subspace methods (CG, GMRES, BiCGSTAB ...) as well as highly efficient preconditioning techniques are presented in the context of real life applications. Hands-on sessions (MATLAB and GNU Octave respectively) will allow users to immediately test and understand the basic constructs of iterative solvers. This course provides scientific training in Computational Science, and in addition, the scientific exchange of the participants among themselves. It is organized by HLRS, IAG, and Uni. Kassel.</p> <p>The guest lecture on Day 2 is offered in collaboration with <a href=\"https://hidalgo-project.eu\"><strong>HiDALGO</strong></a>, the EU Centre of Excellence for Global Challenges. The method exposed is used in the HiDALGO <strong><a href=\"https://hidalgo-project.eu/use-cases/social-networks\">Social Network Pilot</a></strong>.</p>", "markdown_description": "The focus of the course is on modern iterative solvers for large linear systems of equations. Thereby, beside classical schemes and fundamentals of multigrid techniques different modern Krylov subspace methods (CG, GMRES, BiCGSTAB ...) as well as highly efficient preconditioning techniques are presented in the context of real life applications. Hands-on sessions (MATLAB and GNU Octave respectively) will allow users to immediately test and understand the basic constructs of iterative solvers. This course provides scientific training in Computational Science, and in addition, the scientific exchange of the participants among themselves. It is organized by HLRS, IAG, and Uni. Kassel.\n\nThe guest lecture on Day 2 is offered in collaboration with [**HiDALGO**](https://hidalgo-project.eu), the EU Centre of Excellence for Global Challenges. The method exposed is used in the HiDALGO **[Social Network Pilot](https://hidalgo-project.eu/use-cases/social-networks)**.", "summary": "The focus of the course is on modern iterative solvers for large linear systems of equations. Thereby, beside classical schemes and..."}]}, {"@context": "https://schema.org", "@graph": [{"@type": "Event", "name": "Huawei Atlas AI Workshop @ PSNC", "url": "https://moodle.hidalgo-project.eu/course/view.php?id=10", "description": "Please visit the Moodle page.", "eventAttendanceMode": "https://schema.org/OnlineEventAttendanceMode", "eventStatus": "https://schema.org/EventScheduled", "image": {"@type": "ImageObject", "representativeOfPage": "True", "url": "images/FocusCoE_placeholder.webp", "width": 720, "height": 231}, "doorTime": "2021-03-04T11:00:00+0100", "startDate": "2021-03-04T11:00:00+0100", "endDate": "2021-03-04T13:00:00+0100", "@id": "https://hpc-portal.eu/node/865", "isAccessibleForFree": "True", "location": {"@type": "VirtualLocation", "url": "https://moodle.hidalgo-project.eu/course/view.php?id=10", "geo": {"@type": "GeoCoordinates", "latitude": "52.407189801365", "longitude": "16.9531485"}}, "language": ["English"], "sector": ["Research and Academia"], "country": ["Poland"], "projects": ["HiDALGO"], "level": ["Beginner", "Intermediate", "Advanced", "Other"], "online": ["Live (synchronous)"], "html_description": "<p>Please visit the <a href=\"https://moodle.hidalgo-project.eu/course/view.php?id=10\">Moodle page</a>.</p>", "markdown_description": "Please visit the [Moodle page](https://moodle.hidalgo-project.eu/course/view.php?id=10).", "summary": "Please visit the Moodle page."}]}, {"@context": "https://schema.org", "@graph": [{"@type": "Event", "name": "First joint CoEs Technical Workshop", "url": "https://services.excellerat.eu/viewevent/10", "description": "This event, which takes place on 27-29 January 2021, is open to HiDALGO, ChEESE and EXCELLERAT partners. Members of other CoEs may also participate.\n\nJoint CoEs Technical Workshop (27-29 Jan)\n\nAgenda", "eventAttendanceMode": "https://schema.org/OnlineEventAttendanceMode", "eventStatus": "https://schema.org/EventScheduled", "image": {"@type": "ImageObject", "representativeOfPage": "True", "url": "tmp_images/a48e59a1eb2e887ea61ea6385b992247.webp", "width": 720, "height": 360}, "doorTime": "2021-01-27T13:00:00+0100", "startDate": "2021-01-27T13:00:00+0100", "endDate": "2021-01-29T12:15:00+0100", "@id": "https://hpc-portal.eu/node/862", "isAccessibleForFree": "True", "location": {"@type": "VirtualLocation", "url": "https://services.excellerat.eu/viewevent/10", "geo": {"@type": "GeoCoordinates", "latitude": "48.739485700985", "longitude": "9.0973166"}}, "language": ["English"], "sector": ["Research and Academia", "Industry", "Public Sector"], "country": ["Germany"], "projects": ["ChEESE", "EXCELLERAT", "HiDALGO"], "level": ["Intermediate", "Advanced", "Other"], "online": ["Live (synchronous)"], "html_description": "<p>This event, which takes place on 27-29 January 2021, is open to HiDALGO, ChEESE and EXCELLERAT partners. Members of other CoEs may also participate.</p> <p><a href=\"https://www.excellerat.eu/technical-workshop/\">Joint CoEs Technical Workshop (27-29 Jan)</a></p> <p><a href=\"https://docs.google.com/spreadsheets/d/1QHekVGeEYT3SVoog9aN-Gns5GrjCsxOMwuclbCBlDXo/edit#gid=2123902136\">Agenda</a></p>", "markdown_description": "This event, which takes place on 27-29 January 2021, is open to HiDALGO, ChEESE and EXCELLERAT partners. Members of other CoEs may also participate.\n\n[Joint CoEs Technical Workshop (27-29 Jan)](https://www.excellerat.eu/technical-workshop/)\n\n[Agenda](https://docs.google.com/spreadsheets/d/1QHekVGeEYT3SVoog9aN-Gns5GrjCsxOMwuclbCBlDXo/edit#gid=2123902136)", "summary": "This event, which takes place on 27-29 January 2021, is open to HiDALGO, ChEESE and EXCELLERAT partners. Members of other CoEs may..."}]}, {"@context": "https://schema.org", "@graph": [{"@type": "Event", "name": "Tackling global challenges by use of HPC / HPDA and AI Workshop at the HiPEAC Conference", "url": "https://hidalgo-project.eu/hipeac-workshop-2021", "description": "Global challenges, like the spread of diseases, climate change, air pollution, forced migration, the spread of disinformation in social networks and the sustainable use of energy are more emergent and urgent than ever. The use of HPC, HPDA and Artificial Intelligence allows to accurately model and simulate the underlying complex processes.\n\nWithin this workshop several current examples are presented of how HPC, HPDA and AI support the tackling of global challenges. The workshop provides insights into advanced HPC, HPDA and AI technologies to improve data-centric computation. It aims to attract and bring together different stakeholders from the HPC and Big Data and Global Challenges communities.", "eventAttendanceMode": "https://schema.org/OnlineEventAttendanceMode", "eventStatus": "https://schema.org/EventScheduled", "image": {"@type": "ImageObject", "representativeOfPage": "True", "url": "images/FocusCoE_placeholder.webp", "width": 720, "height": 231}, "doorTime": "2021-01-20T13:00:00+0100", "startDate": "2021-01-20T13:00:00+0100", "endDate": "2021-01-20T18:30:00+0100", "@id": "https://hpc-portal.eu/node/974", "isAccessibleForFree": "True", "location": {"@type": "VirtualLocation", "url": "https://www.hipeac.net/2021/budapest/#/", "geo": {"@type": "GeoCoordinates", "latitude": "47.48158349786", "longitude": "19.13001575"}}, "language": ["English"], "sector": ["Research and Academia", "Industry", "Public Sector"], "country": ["Hungary"], "projects": ["ESiWACE2", "HiDALGO"], "level": ["Beginner", "Intermediate", "Advanced"], "online": ["Live (synchronous)"], "html_description": "<p>Global challenges, like the spread of diseases, climate change, air pollution, forced migration, the spread of disinformation in social networks and the sustainable use of energy are more emergent and urgent than ever. The use of HPC, HPDA and Artificial Intelligence allows to accurately model and simulate the underlying complex processes.</p> <p>Within this workshop several current examples are presented of how HPC, HPDA and AI support the tackling of global challenges. The workshop provides insights into advanced HPC, HPDA and AI technologies to improve data-centric computation. It aims to attract and bring together different stakeholders from the HPC and Big Data and Global Challenges communities.</p>", "markdown_description": "Global challenges, like the spread of diseases, climate change, air pollution, forced migration, the spread of disinformation in social networks and the sustainable use of energy are more emergent and urgent than ever. The use of HPC, HPDA and Artificial Intelligence allows to accurately model and simulate the underlying complex processes.\n\nWithin this workshop several current examples are presented of how HPC, HPDA and AI support the tackling of global challenges. The workshop provides insights into advanced HPC, HPDA and AI technologies to improve data-centric computation. It aims to attract and bring together different stakeholders from the HPC and Big Data and Global Challenges communities.", "summary": "Global challenges, like the spread of diseases, climate change, air pollution, forced migration, the spread of disinformation in..."}]}]